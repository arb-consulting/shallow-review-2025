https://docs.google.com/presentation/d/1IxNCFB81jy3_Xf5ogZLYUS8kgRlhRdIVV5EYSb4VfBo/edit?slide=id.g35035bb93ce_0_0
https://docs.google.com/document/d/1rHhOVqLlEMwZYJ7p520P9Qctjj52LlU0y6tza32xENo/edit?tab=t.0#heading=h.xh27vxixs0h6
https://alignment.anthropic.com/
https://docs.google.com/document/d/1Mis0ZxuS-YIgwy4clC7hKrKEcm6Pn0yn709YUNVcpx8/edit?tab=t.0#heading=h.u9eroo3v6v28

https://thezvi.substack.com/p/the-big-nonprofits-post

https://survivalandflourishing.fund/2025/recommendations

https://arxiv.org/pdf/2506.20702

https://aisafetyfrontier.substack.com/

https://alignmentsurvey.com/top10/2024-02-28/

https://docs.google.com/spreadsheets/u/1/d/1XxZGbbyFAeTCxEtGmyE601MB2HduUeSfDh7rXlFF914/htmlview?gid=412375728

https://github.com/rexdouglass/RexReviews?tab=readme-ov-file
https://threadreaderapp.com/thread/1894436637054214509.html

https://www.lesswrong.com/posts/RRvdRyWrSqKW2ANL9/alignment-proposal-adversarially-robust-augmentation-and

https://www.lesswrong.com/posts/AzFxTMFfkTt4mhMKt/alignment-as-uploading-with-more-steps

https://www.alignmentforum.org/posts/LngR93YwiEpJ3kiWh/research-agenda-synthesizing-standalone-world-models#High_Level_Outline

https://x.com/OBalcells/status/1965434564748447921

https://arxiv.org/abs/2507.11473

https://arxiv.org/abs/2506.13609

https://openai.com/index/chain-of-thought-monitoring/

https://www.affi.ne/

https://threadreaderapp.com/thread/1894436637054214509.html

https://www.lesswrong.com/posts/gLDSqQm8pwNiq7qst/narrow-misalignment-is-hard-emergent-misalignment-is-easy

https://arxiv.org/pdf/2506.11613

https://arxiv.org/abs/2506.11618

https://arxiv.org/abs/2506.19823

https://arxiv.org/abs/2506.13206


https://arxiv.org/abs/2502.19649v1

https://underwriting-superintelligence.com/

https://www.lesswrong.com/posts/GoWQT2cPuvLBgXuF9/many-kinds-of-work-one-could-do-to-make-ai-go-better-and-a

https://www.openphilanthropy.org/tais-rfp-research-areas/


https://www.alignmentforum.org/posts/pPEeMdgjpjHZWCDFw/white-box-control-at-uk-aisi-update-on-sandbagging

https://openreview.net/group?id=iliadconference.com/ODYSSEY/2025/Conference#tab-active-submissions

https://x.com/fulcrumML

https://huggingface.co/papers/2502.02649

https://x.com/achan96/status/1881383405453234338

https://x.com/OwainEvans_UK/status/1881767725430976642

https://neural-interactive-proofs.com/

https://x.com/saprmarks/status/1900326393302704494

https://www.prism-eval.ai/

https://x.com/davlindner/status/1882451562859254050

https://windowsontheory.org/2025/01/24/six-thoughts-on-ai-safety/

https://humanfeedback.io/#mission

https://arxiv.org/pdf/2412.12140

https://gradual-disempowerment.ai/

https://manifund.org/projects/safeplanbench-evaluating-a-guaranteed-safe-ai-approach-for-llm-based-agents

https://www.alignmentforum.org/posts/EPefYWjuHNcNH4C7E/attribution-based-parameter-decomposition

https://arxiv.org/pdf/2501.16496

https://alignment.anthropic.com/2024/safety-cases/

https://www.lesswrong.com/posts/bb5Tnjdrptu89rcyY/what-s-the-short-timeline-plan

https://cybercat.institute

https://x.com/AnthropicAI/status/1894495059954860055

https://www.alignmentforum.org/posts/2yLyT6kB7BQvTfEuZ/sharp-left-turn-discourse-an-opinionated-review

https://x.com/tomekkorbak/status/1885014578641228098

https://www.gradientinstitute.org/

https://arxiv.org/abs/2501.18837

https://www.lesswrong.com/posts/YXNeA3RyRrrRWS37A/a-problem-to-solve-before-building-a-deception-detector#F7nbdzdy4pXYWLYHp

https://x.com/abeirami/status/1886399025315729775

https://ai.meta.com/static-resource/meta-frontier-ai-framework/?utm_source=newsroom&utm_medium=web&utm_content=Frontier_AI_Framework_PDF&utm_campaign=Our_Approach_to_Frontier_AI_blog

https://x.com/AISafetyInst/status/1886823790409060737

https://www.aisi.gov.uk/careers/apply?gh_jid=4533688101

https://www.alignmentforum.org/posts/pJ3mDD7LfEwp3s5vG/the-theoretical-reward-learning-research-agenda-introduction

https://alignment.anthropic.com/2025/automated-researchers-sandbag/

https://arxiv.org/abs/2508.17456

https://openai.com/index/chain-of-thought-monitoring/

https://huggingface.co/papers/2502.02649

https://x.com/achan96/status/1881383405453234338

https://arxiv.org/abs/2506.07326

https://x.com/OwainEvans_UK/status/1881767725430976642

https://neural-interactive-proofs.com/

https://prism-eval.ai

https://x.com/davlindner/status/1882451562859254050

https://windowsontheory.org/2025/01/24/six-thoughts-on-ai-safety/

https://humanfeedback.io/#mission

https://arxiv.org/pdf/2412.12140

https://gradual-disempowerment.ai/