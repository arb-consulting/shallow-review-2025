{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "985c1bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfd110a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2036c9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under a velvet moon, a shy unicorn with a silver mane tiptoed through the whispering meadow, leaving trails of starlight that curled into sweet dreams for every sleeping child.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-5\", input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e138cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "prompt = \"\"\"\n",
    "I'm writing a literature review of the field of AI alignment for 2025. My goal is to find the most interesting posts from the past year that represent advancements in the field.\n",
    "\n",
    "You should go through the list of posts and identify posts that seem like an advancement in the field of AI alignment.\n",
    "\n",
    "Here are categories of posts you should keep:\n",
    "- Posts that link to a paper or introduce an advancement in the field of AI alignment\n",
    "- Posts that have high karma\n",
    "- Posts that are high-quality critiques of a specific research agenda\n",
    "- High-quality literature reviews\n",
    "- High quality position posts\n",
    "\n",
    "For each batch of 10 posts, you should typically keep 1-3 of the best posts in the group.\n",
    "\n",
    "If there are multiple exceptionally high-quality posts, you may keep up to 5 posts.\n",
    "\n",
    "For each post, you should output a JSON object with the following fields:\n",
    "- keep: true if the post should be kept, false otherwise\n",
    "- reason: a short reason for keeping or not keeping the post\n",
    "- category: the category of the post (e.g. \"critique\", \"review\", \"position\", \"advancement\")\n",
    "- field: the field of AI alignment that the post is about (e.g. \"interpretability\", \"RL safety\", \"agent foundations\" etc.). Note that you may discover new fields of AI alignment that are not already in the list.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class PostFilteringResponse(BaseModel):\n",
    "    keep: bool\n",
    "    reason: str\n",
    "    category: str\n",
    "    field: str\n",
    "\n",
    "\n",
    "class BatchPostFilteringResponse(BaseModel):\n",
    "    posts: list[PostFilteringResponse]\n",
    "\n",
    "\n",
    "def get_post_content(url: str, max_words: int = 500) -> str:\n",
    "    \"\"\"\n",
    "    Fetch the post content from the URL and return the first max_words words.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Find the main post content (adjust selector based on site structure)\n",
    "        # Alignment Forum typically uses these classes\n",
    "        content_div = soup.find(\"div\", class_=\"PostsPage-postContent\")\n",
    "        if not content_div:\n",
    "            content_div = soup.find(\"article\")\n",
    "        if not content_div:\n",
    "            content_div = soup.find(\"div\", class_=\"post-body\")\n",
    "\n",
    "        if content_div:\n",
    "            # Get all text, removing extra whitespace\n",
    "            text = content_div.get_text(separator=\" \", strip=True)\n",
    "            # Split into words and take first max_words\n",
    "            words = text.split()\n",
    "            truncated_text = \" \".join(words[:max_words])\n",
    "            return truncated_text\n",
    "        else:\n",
    "            return \"Could not extract post content\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching content: {e}\")\n",
    "        return f\"Error fetching content: {str(e)}\"\n",
    "\n",
    "\n",
    "def filter_posts(posts: pd.DataFrame, batch_size: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter the posts and keep only the most interesting ones. Use the AI's output JSON to add new columns to the DataFrame.\n",
    "    Processes posts in batches for efficiency.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total_posts = len(posts)\n",
    "\n",
    "    # Process posts in batches\n",
    "    for batch_start in range(0, total_posts, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, total_posts)\n",
    "        batch_posts = posts.iloc[batch_start:batch_end]\n",
    "\n",
    "        print(\n",
    "            f\"Processing batch: posts {batch_start + 1} to {batch_end} of {total_posts}\"\n",
    "        )\n",
    "\n",
    "        # Fetch content for all posts in the batch\n",
    "        batch_contents = []\n",
    "        for idx, (_, row) in enumerate(batch_posts.iterrows(), 1):\n",
    "            print(f\"  Fetching content for post {batch_start + idx}...\")\n",
    "            content = get_post_content(row[\"link\"], max_words=500)\n",
    "            batch_contents.append(content)\n",
    "            # Longer delay between requests (2-4 seconds with randomization)\n",
    "            time.sleep(random.uniform(2, 4))\n",
    "\n",
    "        # Create a formatted message with all posts in the batch\n",
    "        batch_info = \"Please analyze these posts and return a JSON array with one object for each post. Remember to keep approximately 1 in 10 posts.\\n\\n\"\n",
    "        for idx, (_, row) in enumerate(batch_posts.iterrows(), 1):\n",
    "            batch_info += f\"\"\"Post {idx}:\n",
    "Title: {row[\"title\"]}\n",
    "Karma: {row[\"karma\"]}\n",
    "Date: {row[\"date\"]}\n",
    "Link: {row[\"link\"]}\n",
    "\n",
    "Content (first 500 words):\n",
    "{batch_contents[idx - 1]}\n",
    "\n",
    "---\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.responses.parse(\n",
    "                model=\"gpt-5-mini\",\n",
    "                input=[\n",
    "                    {\"role\": \"system\", \"content\": prompt},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": batch_info,\n",
    "                    },\n",
    "                ],\n",
    "                reasoning={\n",
    "                    \"effort\": \"minimal\",\n",
    "                },\n",
    "                text_format=BatchPostFilteringResponse,\n",
    "            )\n",
    "\n",
    "            parsed_response = response.output_parsed\n",
    "\n",
    "            # Add the response data to results for each post in the batch\n",
    "            for idx, (_, row) in enumerate(batch_posts.iterrows()):\n",
    "                if idx < len(parsed_response.posts):\n",
    "                    post_response = parsed_response.posts[idx]\n",
    "                    results.append(\n",
    "                        {\n",
    "                            \"title\": row[\"title\"],\n",
    "                            \"link\": row[\"link\"],\n",
    "                            \"karma\": row[\"karma\"],\n",
    "                            \"date\": row[\"date\"],\n",
    "                            \"keep\": post_response.keep,\n",
    "                            \"reason\": post_response.reason,\n",
    "                            \"category\": post_response.category,\n",
    "                            \"field\": post_response.field,\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    # Handle case where we got fewer responses than expected\n",
    "                    print(f\"Warning: Missing response for post {batch_start + idx + 1}\")\n",
    "                    results.append(\n",
    "                        {\n",
    "                            \"title\": row[\"title\"],\n",
    "                            \"link\": row[\"link\"],\n",
    "                            \"karma\": row[\"karma\"],\n",
    "                            \"date\": row[\"date\"],\n",
    "                            \"keep\": False,\n",
    "                            \"reason\": \"Missing response from API\",\n",
    "                            \"category\": \"error\",\n",
    "                            \"field\": \"unknown\",\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch starting at post {batch_start + 1}: {e}\")\n",
    "            # Add the original rows with error values for the entire batch\n",
    "            for _, row in batch_posts.iterrows():\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"title\": row[\"title\"],\n",
    "                        \"link\": row[\"link\"],\n",
    "                        \"karma\": row[\"karma\"],\n",
    "                        \"date\": row[\"date\"],\n",
    "                        \"keep\": False,\n",
    "                        \"reason\": f\"Error: {str(e)}\",\n",
    "                        \"category\": \"error\",\n",
    "                        \"field\": \"unknown\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0975bc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: posts 1 to 10 of 438\n",
      "  Fetching content for post 1...\n",
      "  Fetching content for post 2...\n",
      "  Fetching content for post 3...\n",
      "  Fetching content for post 4...\n",
      "  Fetching content for post 5...\n",
      "  Fetching content for post 6...\n",
      "  Fetching content for post 7...\n",
      "  Fetching content for post 8...\n",
      "  Fetching content for post 9...\n",
      "  Fetching content for post 10...\n",
      "Processing batch: posts 11 to 20 of 438\n",
      "  Fetching content for post 11...\n",
      "  Fetching content for post 12...\n",
      "  Fetching content for post 13...\n",
      "  Fetching content for post 14...\n",
      "  Fetching content for post 15...\n",
      "  Fetching content for post 16...\n",
      "  Fetching content for post 17...\n",
      "  Fetching content for post 18...\n",
      "  Fetching content for post 19...\n",
      "  Fetching content for post 20...\n",
      "Processing batch: posts 21 to 30 of 438\n",
      "  Fetching content for post 21...\n",
      "  Fetching content for post 22...\n",
      "  Fetching content for post 23...\n",
      "  Fetching content for post 24...\n",
      "  Fetching content for post 25...\n",
      "  Fetching content for post 26...\n",
      "  Fetching content for post 27...\n",
      "  Fetching content for post 28...\n",
      "  Fetching content for post 29...\n",
      "  Fetching content for post 30...\n",
      "Processing batch: posts 31 to 40 of 438\n",
      "  Fetching content for post 31...\n",
      "  Fetching content for post 32...\n",
      "  Fetching content for post 33...\n",
      "  Fetching content for post 34...\n",
      "  Fetching content for post 35...\n",
      "  Fetching content for post 36...\n",
      "  Fetching content for post 37...\n",
      "  Fetching content for post 38...\n",
      "  Fetching content for post 39...\n",
      "  Fetching content for post 40...\n",
      "Processing batch: posts 41 to 50 of 438\n",
      "  Fetching content for post 41...\n",
      "  Fetching content for post 42...\n",
      "  Fetching content for post 43...\n",
      "  Fetching content for post 44...\n",
      "  Fetching content for post 45...\n",
      "  Fetching content for post 46...\n",
      "  Fetching content for post 47...\n",
      "  Fetching content for post 48...\n",
      "  Fetching content for post 49...\n",
      "  Fetching content for post 50...\n",
      "Processing batch: posts 51 to 60 of 438\n",
      "  Fetching content for post 51...\n",
      "  Fetching content for post 52...\n",
      "  Fetching content for post 53...\n",
      "  Fetching content for post 54...\n",
      "  Fetching content for post 55...\n",
      "  Fetching content for post 56...\n",
      "  Fetching content for post 57...\n",
      "  Fetching content for post 58...\n",
      "  Fetching content for post 59...\n",
      "  Fetching content for post 60...\n",
      "Processing batch: posts 61 to 70 of 438\n",
      "  Fetching content for post 61...\n",
      "  Fetching content for post 62...\n",
      "  Fetching content for post 63...\n",
      "  Fetching content for post 64...\n",
      "  Fetching content for post 65...\n",
      "  Fetching content for post 66...\n",
      "  Fetching content for post 67...\n",
      "  Fetching content for post 68...\n",
      "  Fetching content for post 69...\n",
      "  Fetching content for post 70...\n",
      "Processing batch: posts 71 to 80 of 438\n",
      "  Fetching content for post 71...\n",
      "  Fetching content for post 72...\n",
      "  Fetching content for post 73...\n",
      "  Fetching content for post 74...\n",
      "  Fetching content for post 75...\n",
      "  Fetching content for post 76...\n",
      "  Fetching content for post 77...\n",
      "  Fetching content for post 78...\n",
      "  Fetching content for post 79...\n",
      "  Fetching content for post 80...\n",
      "Processing batch: posts 81 to 90 of 438\n",
      "  Fetching content for post 81...\n",
      "  Fetching content for post 82...\n",
      "  Fetching content for post 83...\n",
      "  Fetching content for post 84...\n",
      "  Fetching content for post 85...\n",
      "  Fetching content for post 86...\n",
      "  Fetching content for post 87...\n",
      "  Fetching content for post 88...\n",
      "  Fetching content for post 89...\n",
      "  Fetching content for post 90...\n",
      "Processing batch: posts 91 to 100 of 438\n",
      "  Fetching content for post 91...\n",
      "  Fetching content for post 92...\n",
      "  Fetching content for post 93...\n",
      "  Fetching content for post 94...\n",
      "  Fetching content for post 95...\n",
      "  Fetching content for post 96...\n",
      "  Fetching content for post 97...\n",
      "  Fetching content for post 98...\n",
      "  Fetching content for post 99...\n",
      "  Fetching content for post 100...\n",
      "Processing batch: posts 101 to 110 of 438\n",
      "  Fetching content for post 101...\n",
      "  Fetching content for post 102...\n",
      "  Fetching content for post 103...\n",
      "  Fetching content for post 104...\n",
      "  Fetching content for post 105...\n",
      "  Fetching content for post 106...\n",
      "  Fetching content for post 107...\n",
      "  Fetching content for post 108...\n",
      "  Fetching content for post 109...\n",
      "  Fetching content for post 110...\n",
      "Processing batch: posts 111 to 120 of 438\n",
      "  Fetching content for post 111...\n",
      "  Fetching content for post 112...\n",
      "  Fetching content for post 113...\n",
      "  Fetching content for post 114...\n",
      "  Fetching content for post 115...\n",
      "  Fetching content for post 116...\n",
      "  Fetching content for post 117...\n",
      "  Fetching content for post 118...\n",
      "  Fetching content for post 119...\n",
      "  Fetching content for post 120...\n",
      "Processing batch: posts 121 to 130 of 438\n",
      "  Fetching content for post 121...\n",
      "  Fetching content for post 122...\n",
      "  Fetching content for post 123...\n",
      "  Fetching content for post 124...\n",
      "  Fetching content for post 125...\n",
      "  Fetching content for post 126...\n",
      "  Fetching content for post 127...\n",
      "  Fetching content for post 128...\n",
      "  Fetching content for post 129...\n",
      "  Fetching content for post 130...\n",
      "Processing batch: posts 131 to 140 of 438\n",
      "  Fetching content for post 131...\n",
      "  Fetching content for post 132...\n",
      "  Fetching content for post 133...\n",
      "  Fetching content for post 134...\n",
      "  Fetching content for post 135...\n",
      "  Fetching content for post 136...\n",
      "  Fetching content for post 137...\n",
      "  Fetching content for post 138...\n",
      "  Fetching content for post 139...\n",
      "  Fetching content for post 140...\n",
      "Processing batch: posts 141 to 150 of 438\n",
      "  Fetching content for post 141...\n",
      "  Fetching content for post 142...\n",
      "  Fetching content for post 143...\n",
      "  Fetching content for post 144...\n",
      "  Fetching content for post 145...\n",
      "  Fetching content for post 146...\n",
      "  Fetching content for post 147...\n",
      "  Fetching content for post 148...\n",
      "  Fetching content for post 149...\n",
      "  Fetching content for post 150...\n",
      "Processing batch: posts 151 to 160 of 438\n",
      "  Fetching content for post 151...\n",
      "  Fetching content for post 152...\n",
      "  Fetching content for post 153...\n",
      "  Fetching content for post 154...\n",
      "  Fetching content for post 155...\n",
      "  Fetching content for post 156...\n",
      "  Fetching content for post 157...\n",
      "  Fetching content for post 158...\n",
      "  Fetching content for post 159...\n",
      "  Fetching content for post 160...\n",
      "Processing batch: posts 161 to 170 of 438\n",
      "  Fetching content for post 161...\n",
      "  Fetching content for post 162...\n",
      "  Fetching content for post 163...\n",
      "  Fetching content for post 164...\n",
      "  Fetching content for post 165...\n",
      "  Fetching content for post 166...\n",
      "  Fetching content for post 167...\n",
      "  Fetching content for post 168...\n",
      "  Fetching content for post 169...\n",
      "  Fetching content for post 170...\n",
      "Processing batch: posts 171 to 180 of 438\n",
      "  Fetching content for post 171...\n",
      "  Fetching content for post 172...\n",
      "  Fetching content for post 173...\n",
      "  Fetching content for post 174...\n",
      "  Fetching content for post 175...\n",
      "  Fetching content for post 176...\n",
      "  Fetching content for post 177...\n",
      "  Fetching content for post 178...\n",
      "  Fetching content for post 179...\n",
      "  Fetching content for post 180...\n",
      "Processing batch: posts 181 to 190 of 438\n",
      "  Fetching content for post 181...\n",
      "  Fetching content for post 182...\n",
      "  Fetching content for post 183...\n",
      "  Fetching content for post 184...\n",
      "  Fetching content for post 185...\n",
      "  Fetching content for post 186...\n",
      "  Fetching content for post 187...\n",
      "  Fetching content for post 188...\n",
      "  Fetching content for post 189...\n",
      "  Fetching content for post 190...\n",
      "Processing batch: posts 191 to 200 of 438\n",
      "  Fetching content for post 191...\n",
      "  Fetching content for post 192...\n",
      "  Fetching content for post 193...\n",
      "  Fetching content for post 194...\n",
      "  Fetching content for post 195...\n",
      "  Fetching content for post 196...\n",
      "  Fetching content for post 197...\n",
      "  Fetching content for post 198...\n",
      "  Fetching content for post 199...\n",
      "  Fetching content for post 200...\n",
      "Processing batch: posts 201 to 210 of 438\n",
      "  Fetching content for post 201...\n",
      "  Fetching content for post 202...\n",
      "  Fetching content for post 203...\n",
      "  Fetching content for post 204...\n",
      "  Fetching content for post 205...\n",
      "  Fetching content for post 206...\n",
      "  Fetching content for post 207...\n",
      "  Fetching content for post 208...\n",
      "  Fetching content for post 209...\n",
      "  Fetching content for post 210...\n",
      "Processing batch: posts 211 to 220 of 438\n",
      "  Fetching content for post 211...\n",
      "  Fetching content for post 212...\n",
      "  Fetching content for post 213...\n",
      "  Fetching content for post 214...\n",
      "  Fetching content for post 215...\n",
      "  Fetching content for post 216...\n",
      "  Fetching content for post 217...\n",
      "  Fetching content for post 218...\n",
      "  Fetching content for post 219...\n",
      "  Fetching content for post 220...\n",
      "Processing batch: posts 221 to 230 of 438\n",
      "  Fetching content for post 221...\n",
      "  Fetching content for post 222...\n",
      "  Fetching content for post 223...\n",
      "  Fetching content for post 224...\n",
      "  Fetching content for post 225...\n",
      "  Fetching content for post 226...\n",
      "  Fetching content for post 227...\n",
      "  Fetching content for post 228...\n",
      "  Fetching content for post 229...\n",
      "  Fetching content for post 230...\n",
      "Processing batch: posts 231 to 240 of 438\n",
      "  Fetching content for post 231...\n",
      "  Fetching content for post 232...\n",
      "  Fetching content for post 233...\n",
      "  Fetching content for post 234...\n",
      "  Fetching content for post 235...\n",
      "  Fetching content for post 236...\n",
      "  Fetching content for post 237...\n",
      "  Fetching content for post 238...\n",
      "  Fetching content for post 239...\n",
      "  Fetching content for post 240...\n",
      "Processing batch: posts 241 to 250 of 438\n",
      "  Fetching content for post 241...\n",
      "  Fetching content for post 242...\n",
      "  Fetching content for post 243...\n",
      "  Fetching content for post 244...\n",
      "  Fetching content for post 245...\n",
      "  Fetching content for post 246...\n",
      "  Fetching content for post 247...\n",
      "  Fetching content for post 248...\n",
      "  Fetching content for post 249...\n",
      "  Fetching content for post 250...\n",
      "Processing batch: posts 251 to 260 of 438\n",
      "  Fetching content for post 251...\n",
      "  Fetching content for post 252...\n",
      "  Fetching content for post 253...\n",
      "  Fetching content for post 254...\n",
      "  Fetching content for post 255...\n",
      "  Fetching content for post 256...\n",
      "  Fetching content for post 257...\n",
      "  Fetching content for post 258...\n",
      "  Fetching content for post 259...\n",
      "  Fetching content for post 260...\n",
      "Processing batch: posts 261 to 270 of 438\n",
      "  Fetching content for post 261...\n",
      "  Fetching content for post 262...\n",
      "  Fetching content for post 263...\n",
      "  Fetching content for post 264...\n",
      "  Fetching content for post 265...\n",
      "  Fetching content for post 266...\n",
      "  Fetching content for post 267...\n",
      "  Fetching content for post 268...\n",
      "  Fetching content for post 269...\n",
      "  Fetching content for post 270...\n",
      "Processing batch: posts 271 to 280 of 438\n",
      "  Fetching content for post 271...\n",
      "  Fetching content for post 272...\n",
      "  Fetching content for post 273...\n",
      "  Fetching content for post 274...\n",
      "  Fetching content for post 275...\n",
      "  Fetching content for post 276...\n",
      "  Fetching content for post 277...\n",
      "  Fetching content for post 278...\n",
      "  Fetching content for post 279...\n",
      "  Fetching content for post 280...\n",
      "Processing batch: posts 281 to 290 of 438\n",
      "  Fetching content for post 281...\n",
      "  Fetching content for post 282...\n",
      "  Fetching content for post 283...\n",
      "  Fetching content for post 284...\n",
      "  Fetching content for post 285...\n",
      "  Fetching content for post 286...\n",
      "  Fetching content for post 287...\n",
      "  Fetching content for post 288...\n",
      "  Fetching content for post 289...\n",
      "  Fetching content for post 290...\n",
      "Processing batch: posts 291 to 300 of 438\n",
      "  Fetching content for post 291...\n",
      "  Fetching content for post 292...\n",
      "  Fetching content for post 293...\n",
      "  Fetching content for post 294...\n",
      "  Fetching content for post 295...\n",
      "  Fetching content for post 296...\n",
      "  Fetching content for post 297...\n",
      "  Fetching content for post 298...\n",
      "  Fetching content for post 299...\n",
      "  Fetching content for post 300...\n",
      "Processing batch: posts 301 to 310 of 438\n",
      "  Fetching content for post 301...\n",
      "  Fetching content for post 302...\n",
      "  Fetching content for post 303...\n",
      "  Fetching content for post 304...\n",
      "  Fetching content for post 305...\n",
      "  Fetching content for post 306...\n",
      "  Fetching content for post 307...\n",
      "  Fetching content for post 308...\n",
      "  Fetching content for post 309...\n",
      "  Fetching content for post 310...\n",
      "Processing batch: posts 311 to 320 of 438\n",
      "  Fetching content for post 311...\n",
      "  Fetching content for post 312...\n",
      "  Fetching content for post 313...\n",
      "  Fetching content for post 314...\n",
      "  Fetching content for post 315...\n",
      "  Fetching content for post 316...\n",
      "  Fetching content for post 317...\n",
      "  Fetching content for post 318...\n",
      "  Fetching content for post 319...\n",
      "  Fetching content for post 320...\n",
      "Processing batch: posts 321 to 330 of 438\n",
      "  Fetching content for post 321...\n",
      "  Fetching content for post 322...\n",
      "  Fetching content for post 323...\n",
      "  Fetching content for post 324...\n",
      "  Fetching content for post 325...\n",
      "  Fetching content for post 326...\n",
      "  Fetching content for post 327...\n",
      "  Fetching content for post 328...\n",
      "  Fetching content for post 329...\n",
      "  Fetching content for post 330...\n",
      "Processing batch: posts 331 to 340 of 438\n",
      "  Fetching content for post 331...\n",
      "  Fetching content for post 332...\n",
      "  Fetching content for post 333...\n",
      "  Fetching content for post 334...\n",
      "  Fetching content for post 335...\n",
      "  Fetching content for post 336...\n",
      "  Fetching content for post 337...\n",
      "  Fetching content for post 338...\n",
      "  Fetching content for post 339...\n",
      "  Fetching content for post 340...\n",
      "Processing batch: posts 341 to 350 of 438\n",
      "  Fetching content for post 341...\n",
      "  Fetching content for post 342...\n",
      "  Fetching content for post 343...\n",
      "  Fetching content for post 344...\n",
      "  Fetching content for post 345...\n",
      "  Fetching content for post 346...\n",
      "  Fetching content for post 347...\n",
      "  Fetching content for post 348...\n",
      "  Fetching content for post 349...\n",
      "  Fetching content for post 350...\n",
      "Processing batch: posts 351 to 360 of 438\n",
      "  Fetching content for post 351...\n",
      "  Fetching content for post 352...\n",
      "  Fetching content for post 353...\n",
      "  Fetching content for post 354...\n",
      "  Fetching content for post 355...\n",
      "  Fetching content for post 356...\n",
      "  Fetching content for post 357...\n",
      "  Fetching content for post 358...\n",
      "  Fetching content for post 359...\n",
      "  Fetching content for post 360...\n",
      "Processing batch: posts 361 to 370 of 438\n",
      "  Fetching content for post 361...\n",
      "  Fetching content for post 362...\n",
      "  Fetching content for post 363...\n",
      "  Fetching content for post 364...\n",
      "  Fetching content for post 365...\n",
      "  Fetching content for post 366...\n",
      "  Fetching content for post 367...\n",
      "  Fetching content for post 368...\n",
      "  Fetching content for post 369...\n",
      "  Fetching content for post 370...\n",
      "Processing batch: posts 371 to 380 of 438\n",
      "  Fetching content for post 371...\n",
      "  Fetching content for post 372...\n",
      "  Fetching content for post 373...\n",
      "  Fetching content for post 374...\n",
      "  Fetching content for post 375...\n",
      "  Fetching content for post 376...\n",
      "  Fetching content for post 377...\n",
      "  Fetching content for post 378...\n",
      "  Fetching content for post 379...\n",
      "  Fetching content for post 380...\n",
      "Processing batch: posts 381 to 390 of 438\n",
      "  Fetching content for post 381...\n",
      "  Fetching content for post 382...\n",
      "  Fetching content for post 383...\n",
      "  Fetching content for post 384...\n",
      "  Fetching content for post 385...\n",
      "  Fetching content for post 386...\n",
      "  Fetching content for post 387...\n",
      "  Fetching content for post 388...\n",
      "  Fetching content for post 389...\n",
      "  Fetching content for post 390...\n",
      "Processing batch: posts 391 to 400 of 438\n",
      "  Fetching content for post 391...\n",
      "  Fetching content for post 392...\n",
      "  Fetching content for post 393...\n",
      "  Fetching content for post 394...\n",
      "  Fetching content for post 395...\n",
      "  Fetching content for post 396...\n",
      "  Fetching content for post 397...\n",
      "  Fetching content for post 398...\n",
      "  Fetching content for post 399...\n",
      "  Fetching content for post 400...\n",
      "Processing batch: posts 401 to 410 of 438\n",
      "  Fetching content for post 401...\n",
      "  Fetching content for post 402...\n",
      "  Fetching content for post 403...\n",
      "  Fetching content for post 404...\n",
      "  Fetching content for post 405...\n",
      "  Fetching content for post 406...\n",
      "  Fetching content for post 407...\n",
      "  Fetching content for post 408...\n",
      "  Fetching content for post 409...\n",
      "  Fetching content for post 410...\n",
      "Processing batch: posts 411 to 420 of 438\n",
      "  Fetching content for post 411...\n",
      "  Fetching content for post 412...\n",
      "  Fetching content for post 413...\n",
      "  Fetching content for post 414...\n",
      "  Fetching content for post 415...\n",
      "  Fetching content for post 416...\n",
      "  Fetching content for post 417...\n",
      "  Fetching content for post 418...\n",
      "  Fetching content for post 419...\n",
      "  Fetching content for post 420...\n",
      "Processing batch: posts 421 to 430 of 438\n",
      "  Fetching content for post 421...\n",
      "  Fetching content for post 422...\n",
      "  Fetching content for post 423...\n",
      "  Fetching content for post 424...\n",
      "  Fetching content for post 425...\n",
      "  Fetching content for post 426...\n",
      "  Fetching content for post 427...\n",
      "  Fetching content for post 428...\n",
      "  Fetching content for post 429...\n",
      "  Fetching content for post 430...\n",
      "Processing batch: posts 431 to 438 of 438\n",
      "  Fetching content for post 431...\n",
      "  Fetching content for post 432...\n",
      "  Fetching content for post 433...\n",
      "  Fetching content for post 434...\n",
      "  Fetching content for post 435...\n",
      "  Fetching content for post 436...\n",
      "  Fetching content for post 437...\n",
      "  Fetching content for post 438...\n",
      "\n",
      "Total posts: 438\n",
      "Posts to keep: 173\n",
      "Percentage kept: 39.5%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Usage example:\n",
    "input_df = pd.read_csv(\"all-alignment-forum-posts-2025.csv\")\n",
    "output_df = filter_posts(input_df)\n",
    "output_df.to_csv(\"filtered-alignment-forum-posts-2025-3.csv\", index=False)\n",
    "\n",
    "# Show summary\n",
    "kept_posts = output_df[output_df[\"keep\"] == True]\n",
    "print(f\"\\nTotal posts: {len(output_df)}\")\n",
    "print(f\"Posts to keep: {len(kept_posts)}\")\n",
    "print(f\"Percentage kept: {len(kept_posts) / len(output_df) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7a38fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_posts.to_csv(\"alignment-forum-posts-2025-ai-filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e890f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
